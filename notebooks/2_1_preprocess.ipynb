{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_1_preprocess.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyP31lWz11HIT0wV8HIAU2sL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"cO3ZdYJ8gVGG","executionInfo":{"status":"ok","timestamp":1620537157892,"user_tz":-540,"elapsed":809,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}}},"source":["# masked pseudo labeling [preprocess]"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"4yfMlP8LeUBG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620537198263,"user_tz":-540,"elapsed":41174,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}},"outputId":"e171df77-61c9-48fd-b007-c35fa04c60de"},"source":["from google.colab import drive, files\n","import os\n","\n","drive.mount('/content/drive')  # drive をマウント\n","COLAB = \"/content/drive/MyDrive/studentcup-2021-spring\"  # colaboratory の path (必要時応じて変更)\n","os.chdir(COLAB)\n","!pip install --quiet category_encoders\n","!pip install --quiet xfeat"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","\u001b[K     |████████████████████████████████| 81kB 3.4MB/s \n","\u001b[K     |████████████████████████████████| 296kB 8.0MB/s \n","\u001b[K     |████████████████████████████████| 81kB 4.9MB/s \n","\u001b[K     |████████████████████████████████| 1.2MB 8.5MB/s \n","\u001b[K     |████████████████████████████████| 112kB 22.4MB/s \n","\u001b[K     |████████████████████████████████| 143kB 13.0MB/s \n","\u001b[K     |████████████████████████████████| 51kB 4.1MB/s \n","\u001b[K     |████████████████████████████████| 81kB 6.2MB/s \n","\u001b[?25h  Building wheel for ml-metrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"86RtdwEkfWQ9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620537198605,"user_tz":-540,"elapsed":41514,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}},"outputId":"3f98b987-3a47-42fb-9194-45bb730613ec"},"source":["import requests\n","import os\n","\n","# make config\n","OUTPUT = os.path.join(COLAB, 'output')\n","INPUT = os.path.join(COLAB, 'input')\n","SUBMISSION = os.path.join(COLAB, 'submission')\n","EXP_NAME = \"run2\"\n","EXP = os.path.join(OUTPUT, EXP_NAME)\n","PREDS = os.path.join(EXP, \"preds\")\n","TRAINED = os.path.join(EXP, \"trained\")\n","FEATURE = os.path.join(EXP, \"feature\")\n","REPORTS = os.path.join(EXP, \"reports\")\n","\n","# make experiments environment\n","dirs = [OUTPUT,\n","        SUBMISSION,\n","        FEATURE,\n","        EXP,\n","        PREDS,\n","        TRAINED,\n","        REPORTS]\n","\n","for v in dirs:\n","    if not os.path.isdir(v):\n","        print(f\"making {v}\")\n","        os.makedirs(v)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["making /content/drive/MyDrive/studentcup-2021-spring/output/run2/feature\n","making /content/drive/MyDrive/studentcup-2021-spring/output/run2/preds\n","making /content/drive/MyDrive/studentcup-2021-spring/output/run2/trained\n","making /content/drive/MyDrive/studentcup-2021-spring/output/run2/reports\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gT2OQtksfjIC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620537205100,"user_tz":-540,"elapsed":48005,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}},"outputId":"52713489-b610-4ebf-da00-9aad25f373f0"},"source":["import datetime\n","import logging\n","import random\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.figure_factory as ff\n","import joblib\n","from matplotlib_venn import venn2\n","from sklearn import model_selection\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.cluster import KMeans\n","\n","import itertools\n","\n","from lightgbm import LGBMModel\n","import category_encoders as ce\n","import xfeat\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras import layers as L\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning:\n","\n","pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"rlzHOv9tWeER","executionInfo":{"status":"ok","timestamp":1620537205104,"user_tz":-540,"elapsed":48008,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}}},"source":["# seed 固定\n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","seed_everything(46)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"7HGSHh8XfkL8","executionInfo":{"status":"ok","timestamp":1620537205105,"user_tz":-540,"elapsed":48007,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}}},"source":["# model save and load 用のクラス\n","class Util:\n","    @classmethod\n","    def dump(cls, value, path):\n","        os.makedirs(os.path.dirname(path), exist_ok=True)\n","        joblib.dump(value, path, compress=True)\n","\n","    @classmethod\n","    def load(cls, path):\n","        return joblib.load(path)\n","\n","# log 用のクラス\n","class Logger:\n","    def __init__(self, path):\n","        self.general_logger = logging.getLogger(path)\n","        stream_handler = logging.StreamHandler()\n","        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n","        if len(self.general_logger.handlers) == 0:\n","            self.general_logger.addHandler(stream_handler)\n","            self.general_logger.addHandler(file_general_handler)\n","            self.general_logger.setLevel(logging.INFO)\n","\n","    def info(self, message):\n","        # display time\n","        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n","\n","    @staticmethod\n","    def now_string():\n","        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n","\n","# logger の設定\n","logger = Logger(REPORTS)\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C6HhCgodfqA2"},"source":["## laod data - pseudo labeling -"]},{"cell_type":"code","metadata":{"id":"QLfXo6MTfmc0","executionInfo":{"status":"ok","timestamp":1620537206042,"user_tz":-540,"elapsed":48942,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}}},"source":["train = pd.read_csv(INPUT+\"/train.csv\")\n","test = pd.read_csv(INPUT+\"/test.csv\")\n","sample_sub = pd.read_csv(INPUT+\"/sample_submit.csv\")\n","genre_labels = pd.read_csv(INPUT+\"/genre_labels.csv\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QdiPyz-B3OLB","executionInfo":{"status":"ok","timestamp":1620537206791,"user_tz":-540,"elapsed":49686,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}},"outputId":"de4f0346-76af-405c-f65c-86c76090afae"},"source":["# pseudo labeling augmentation\n","threshold = 0.7\n","\n","path_1 =  \"output/run1/preds\"\n","preds_1 = Util.load(path_1 + \"/preds.pkl\")\n","\n","pseudo = test.copy()\n","pseudo[\"genre\"] = np.argmax(preds_1, axis=1)\n","pseudo[\"proba\"] = np.max(preds_1, axis=1)\n","\n","# cross pseudo labeling 用の flag\n","pseudo[\"flag\"] = 1\n","train[\"flag\"] = 0\n","\n","pseudo = pseudo[pseudo[\"proba\"] >= threshold][train.columns]\n","\n","# augment\n","old = len(train)\n","train = pd.concat([train, pseudo]).reset_index(drop=True)\n","new = len(train)\n","\n","logger.info(f\"Psudo Labeling : {old} -> {new}\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[2021-05-09 05:13:27] - Psudo Labeling : 4046 -> 6624\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"-DZZT0VNfsf0"},"source":["## feature engineering"]},{"cell_type":"code","metadata":{"id":"hTzhT7NOfuuQ","executionInfo":{"status":"ok","timestamp":1620537206791,"user_tz":-540,"elapsed":49685,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}}},"source":["class GroupingEngine: \n","\n","    def __init__(self, group_key, group_values, agg_methods):\n","        self.group_key = group_key\n","        self.group_values = group_values  # debug\n","\n","        ex_trans_methods = [\"val-mean\", \"z-score\"]\n","        self.ex_trans_methods = [m for m in agg_methods if m in ex_trans_methods]\n","        self.agg_methods = [m for m in agg_methods if m not in self.ex_trans_methods]\n","        self.df = None\n","\n","    def fit(self, input_df, y=None):\n","        if not self.agg_methods:\n","            return\n","            \n","        new_df = []\n","        for agg_method in self.agg_methods:\n","\n","            for col in self.group_values:\n","                if callable(agg_method):\n","                    agg_method_name = agg_method.__name__\n","                else:\n","                    agg_method_name = agg_method\n","\n","                new_col = f\"agg_{agg_method_name}_{col}_grpby_{self.group_key}\"\n","                df_agg = (input_df[[col] + [self.group_key]].groupby(self.group_key)[[col]].agg(agg_method))\n","                df_agg.columns = [new_col]\n","                new_df.append(df_agg)\n","        self.df = pd.concat(new_df, axis=1).reset_index()\n","\n","    def transform(self, input_df):\n","        if self.agg_methods:\n","            output_df = pd.merge(input_df[[self.group_key]], self.df, on=self.group_key, how=\"left\")\n","        else:\n","            output_df = input_df[[self.group_key]].copy()\n","\n","        if len(self.ex_trans_methods) != 0:\n","            output_df = self.ex_transform(input_df, output_df)\n","        output_df.drop(self.group_key, axis=1, inplace=True)\n","        return output_df\n","\n","    def ex_transform(self, df1, df2):\n","        \"\"\"\n","        df1: input_df\n","        df2: output_df\n","        return: output_df (added ex transformed features)\n","        \"\"\"\n","\n","        if \"val-mean\" in self.ex_trans_methods:\n","            _agg_df = xfeat.aggregation(df1, \n","                                        group_key=self.group_key,\n","                                        group_values=self.group_values, \n","                                        agg_methods=[\"mean\"])[0]\n","            df2[self._get_col(\"val-mean\")] = df1[self.group_values].values - _agg_df[self._get_col(\"mean\")].values\n","\n","        if \"z-score\" in self.ex_trans_methods:\n","            _agg_df = xfeat.aggregation(df1, \n","                                        group_key=self.group_key,\n","                                        group_values=self.group_values, \n","                                        agg_methods=[\"mean\", \"std\"])[0]\n","            df2[self._get_col(\"z-score\")] = ((df1[self.group_values].values - _agg_df[self._get_col(\"mean\")].values) \n","                                                / (_agg_df[self._get_col(\"std\")].values + 1e-8))\n","\n","        return df2\n","\n","    def _get_col(self, method):\n","        return [f\"agg_{method}_{group_val}_grpby_{self.group_key}\" for group_val in self.group_values]\n","\n","    def fit_transform(self, input_df, y=None):\n","        self.fit(input_df, y=y)\n","        return self.transform(input_df)\n","\n","\n","\n","class TargetEncodingEngine:\n","    \"\"\"\n","    refer to https://github.com/nyk510/atmacup10\n","    \"\"\"\n","\n","    def __init__(self, use_columns, cv):\n","\n","        self.mapping_df_ = None\n","        self.y_mean_ = None\n","        self.use_columns = use_columns\n","        self.cv = list(cv)\n","        self.n_fold = len(self.cv)\n","\n","    def create_mapping(self, input_df, y):\n","        self.mapping_df_ = {}\n","        self.y_mean_ = np.mean(y)\n","\n","        out_df = pd.DataFrame()\n","        target = pd.Series(y)\n","\n","        for col_name in self.use_columns:\n","            keys = input_df[col_name].unique()\n","            x = input_df[col_name]\n","\n","            oof = np.zeros_like(x, dtype=np.float)\n","\n","            for idx_train, idx_valid in self.cv:\n","                _df = target[idx_train].groupby(x[idx_train]).mean()\n","                _df = _df.reindex(keys)\n","                _df = _df.fillna(_df.mean())\n","                oof[idx_valid] = input_df[col_name][idx_valid].map(_df.to_dict())\n","\n","            out_df[col_name] = oof\n","\n","            self.mapping_df_[col_name] = target.groupby(x).mean()\n","\n","        return out_df\n","\n","    def fit(self, input_df: pd.DataFrame, y=None, **kwargs) -> None:\n","        _ = self.create_mapping(input_df, y=y)\n","\n","    def transform(self, input_df: pd.DataFrame) -> pd.DataFrame:\n","        out_df = pd.DataFrame()\n","\n","        for c in self.use_columns:\n","            out_df[c] = input_df[c].map(self.mapping_df_[c]).fillna(self.y_mean_)\n","\n","        return out_df.add_prefix('TE_') \n","\n","    \n","    def fit_transform(self, input_df, y=None):\n","        self.fit(input_df, y=y)\n","        return self.transform(input_df)   "],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"kQwEX2jzfxEI","executionInfo":{"status":"ok","timestamp":1620537206990,"user_tz":-540,"elapsed":49882,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}}},"source":["# 実際に前処理をする関数を定義\n","def get_numerical_features(input_df):\n","    # そのままの数値特徴\n","    cols = ['popularity',\n","            'duration_ms',\n","            'acousticness',\n","            'positiveness',\n","            'danceability',\n","            'loudness',\n","            'energy',\n","            'liveness',\n","            'speechiness',\n","            'instrumentalness']\n","    output_df = input_df[cols].copy()\n","    return output_df.add_prefix(\"lgb__\")\n","\n","\n","def get_ce_features(input_df):\n","    # count encording した特徴量\n","    tmp = input_df[\"popularity\"].astype(str).str.zfill(2)\n","    tmp = pd.Series([i[0] for i in tmp])\n","    _input_df = input_df.copy()\n","    _input_df[\"pop10region\"] = tmp + input_df[\"region\"]\n","\n","    cols = [\"region\", \"pop10region\"]\n","    encoder = ce.CountEncoder()\n","    output_df = encoder.fit_transform(_input_df[cols]).add_prefix(\"CE_\")\n","    return output_df.add_prefix(\"lgb__\")\n","\n","\n","def get_oe_features(input_df):\n","    # ordinal encording (label encording)した特徴量\n","    tmp = input_df[\"popularity\"].astype(str).str.zfill(2)\n","    tmp = pd.Series([i[0] for i in tmp])\n","    _input_df = input_df.copy()\n","    _input_df[\"pop10region\"] = tmp + input_df[\"region\"]\n","    cols = [\"region\", \"pop10region\"]\n","    encoder = ce.OrdinalEncoder()\n","    output_df = encoder.fit_transform(_input_df[cols]).add_prefix(\"OE_\")\n","    return output_df.add_prefix(\"lgb__\")\n","\n","\n","def get_tmpo_features(input_df):\n","    # tmpo に関する特徴量\n","    _df = input_df[\"tempo\"].str.split(\"-\").apply(pd.Series).astype(float)\n","    _df.columns = [\"tempo_low\", \"tempo_high\"]\n","    output_df = _df.copy()\n","    output_df[\"diff_tempo\"] = _df[\"tempo_high\"] - _df[\"tempo_low\"]\n","    return output_df.add_prefix(\"lgb__\")\n","\n","\n","def get_binned_popularity_features(input_df):\n","    # popularity の10の位と1の位の特徴量\n","    tmp = input_df[\"popularity\"].astype(str).str.zfill(2)\n","    tmp = [[i[0], i[1]] for i in tmp]\n","    output_df = pd.DataFrame(tmp, columns=[\"popularity10\", \"popularity01\"])\n","    return output_df.astype(int).add_prefix(\"lgb__\")\n","\n","# 集約特徴量作成時に使用\n","def max_min(x):\n","    return x.max() - x.min()\n","\n","def q75_q25(x):\n","    return x.quantile(0.75) - x.quantile(0.25)\n","\n","\n","def get_agg_region_features(input_df):\n","    # region をキーにした集約特徴量\n","    _input_df = pd.concat([get_tmpo_features(input_df),\n","                           input_df], axis=1)\n","    group_key = \"region\"\n","    group_values = ['popularity',\n","                    'duration_ms',\n","                    'acousticness',\n","                    'positiveness',\n","                    'danceability',\n","                    'loudness',\n","                    'energy',\n","                    'liveness',\n","                    'speechiness',\n","                    'instrumentalness', \n","                    ]\n","    agg_methods = [\"min\", \"mean\", \"max\", max_min, \"z-score\", \"var\", \"skew\", pd.DataFrame.kurt]\n","    encoder = GroupingEngine(group_key=group_key, group_values=group_values, agg_methods=agg_methods)\n","    output_df = encoder.fit_transform(_input_df)\n","    return output_df.add_prefix(\"lgb__\")\n","\n","\n","def get_agg_pop10region_features(input_df):\n","    tmp = input_df[\"popularity\"].astype(str).str.zfill(2)\n","    tmp = pd.Series([i[0] for i in tmp])\n","    _input_df = pd.concat([input_df, \n","                           get_tmpo_features(input_df)], axis=1)\n","    _input_df[\"pop10region\"] = tmp + input_df[\"region\"]\n","    group_key = \"pop10region\"\n","    group_values = ['popularity',\n","                    'duration_ms',\n","                    'acousticness',\n","                    'positiveness',\n","                    'danceability',\n","                    'loudness',\n","                    'energy',\n","                    'liveness',\n","                    'speechiness',\n","                    'instrumentalness',\n","                    ]\n","    agg_methods = [\"min\", \"mean\", \"max\", max_min, \"z-score\", \"var\", \"skew\", pd.DataFrame.kurt]\n","    encoder = GroupingEngine(group_key=group_key, group_values=group_values, agg_methods=agg_methods)\n","    output_df = encoder.fit_transform(_input_df)\n","    return output_df.add_prefix(\"lgb__\")\n","\n","def get_num_nan_features(input_df):\n","    output_df = pd.DataFrame()\n","    output_df[\"num_nan\"] = input_df.isnull().sum(axis=1)\n","    return output_df.add_prefix(\"lgb__\")\n","\n","\n","def get_target_encode_features(input_df):\n","    kf = model_selection.KFold(n_splits=10, random_state=2021, shuffle=True)\n","    tmp = input_df[\"popularity\"].astype(str).str.zfill(2)\n","    tmp = pd.Series([i[0] for i in tmp])\n","    _input_df = input_df.copy()\n","    _input_df[\"pop10region\"] = tmp + input_df[\"region\"]\n","\n","    train_df = _input_df[_input_df[\"genre\"].notnull()]\n","    train_y = ce.OneHotEncoder().fit_transform(train_df[\"genre\"].astype(str))\n","    genre = ['country',\n","             'electronic',\n","             'folk',\n","             'hip-hop',\n","             'jazz',\n","             'latin',\n","             'classic',\n","             'other-light-music',\n","             'pop',\n","             'religious',\n","             'rock']\n","    train_y.columns = genre\n","    out_lst = []\n","    for col in genre:\n","        _y = train_y[col]\n","        encoder = TargetEncodingEngine(use_columns=[\"region\", \"pop10region\"],\n","                                       cv=kf.split(train_df, _y))\n","        encoder.fit(input_df=train_df, y=_y)\n","\n","        out_df = encoder.transform(_input_df).add_suffix(f\"={col}\")\n","        out_lst.append(out_df)\n","    \n","    output_df = pd.concat(out_lst, axis=1)\n","    return output_df.add_prefix(\"lgb__\")\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z1NTUXa1tBV8","executionInfo":{"status":"ok","timestamp":1620537206990,"user_tz":-540,"elapsed":49881,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}}},"source":["# kNN features (nagiss's features)\n","def get_knn_numerical_features(input_df):\n","    cols = ['popularity',\n","            'duration_ms',\n","            'acousticness',\n","            'positiveness',\n","            'danceability',\n","            'loudness',\n","            'energy',\n","            'liveness',\n","            'speechiness',\n","            'instrumentalness']\n","\n","    output_df = input_df[cols + [\"region\"]]\n","    f = lambda x: x.fillna(x.mean())\n","    output_df = output_df.groupby('region').transform(f)\n","\n","    output_df = pd.DataFrame(StandardScaler().fit_transform(output_df), columns=cols)\n","    output_df[\"popularity8\"] = output_df[\"popularity\"] * 8\n","    return output_df.add_prefix(\"kNN__\")\n","\n","\n","def get_knn_ohe_features(input_df):\n","    # ordinal encording (label encording)した特徴量\n","\n","    cols = [\"region\"]\n","    encoder = ce.OneHotEncoder()\n","    output_df = encoder.fit_transform(input_df[cols]).add_prefix(\"OHE_\")* 100\n","    return output_df.add_prefix(\"kNN__\") \n","\n","\n","def get_knn_tmpo_features(input_df):\n","    # tmpo に関する特徴量\n","    _df = input_df[\"tempo\"].str.split(\"-\").apply(pd.Series).astype(float)\n","    _df.columns = [\"tempo_low\", \"tempo_high\"]\n","\n","    _df[\"region\"] = input_df[\"region\"].copy()\n","    f = lambda x: x.fillna(x.mean())\n","    _df = _df.groupby('region').transform(f)\n","\n","    output_df = np.log1p(_df)\n","    return output_df.add_prefix(\"kNN__\") * 0.01\n","\n","\n","def get_knn_num_nan_features(input_df):\n","    output_df = pd.DataFrame()\n","    output_df[\"num_nan\"] = input_df.drop(\"genre\", axis=1).isnull().sum(axis=1)\n","    return output_df.add_prefix(\"kNN__\") * 100\n","\n","\n","def get_knn_target_encode_features(input_df):\n","    kf = model_selection.KFold(n_splits=10, random_state=2021, shuffle=True)\n","    tmp = input_df[\"popularity\"].astype(str).str.zfill(2)\n","    tmp = pd.Series([i[0] for i in tmp])\n","    _input_df = input_df.copy()\n","    _input_df[\"pop10region\"] = tmp + input_df[\"region\"]\n","\n","    train_df = _input_df[_input_df[\"genre\"].notnull()]\n","    train_y = ce.OneHotEncoder().fit_transform(train_df[\"genre\"].astype(str))\n","    genre = ['country',\n","             'electronic',\n","             'folk',\n","             'hip-hop',\n","             'jazz',\n","             'latin',\n","             'classic',\n","             'other-light-music',\n","             'pop',\n","             'religious',\n","             'rock']\n","    train_y.columns = genre\n","    out_lst = []\n","    for col in genre:\n","        _y = train_y[col]\n","        encoder = TargetEncodingEngine(use_columns=[\"pop10region\"],\n","                                       cv=kf.split(train_df, _y))\n","        encoder.fit(input_df=train_df, y=_y)\n","\n","        out_df = encoder.transform(_input_df).add_suffix(f\"={col}\")\n","        out_lst.append(out_df)\n","    \n","    output_df = pd.concat(out_lst, axis=1).fillna(0)\n","    return output_df.add_prefix(\"kNN__\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"OU9H3cLZ3Dy9","executionInfo":{"status":"ok","timestamp":1620537207270,"user_tz":-540,"elapsed":50160,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}}},"source":["# MLP\n","def get_mlp_numerical_features(input_df):\n","    # そのままの数値特徴\n","    cols = ['popularity',\n","            'duration_ms',\n","            'acousticness',\n","            'positiveness',\n","            'danceability',\n","            'loudness',\n","            'energy',\n","            'liveness',\n","            'speechiness',\n","            'instrumentalness']\n","    output_df = input_df[cols].fillna(0).copy()\n","    return output_df.add_prefix(\"MLP__\")\n","\n","\n","def get_mlp_ce_features(input_df):\n","    # count encording した特徴量\n","    _input_df = pd.concat([input_df,\n","                           get_binned_popularity_features(input_df)], axis=1).fillna(0)\n","    \n","    cols = [\"region\"]\n","    encoder = ce.CountEncoder()\n","    output_df = encoder.fit_transform(_input_df[cols]).add_prefix(\"CE_\")\n","    return output_df.add_prefix(\"MLP__\")\n","\n","\n","def get_mlp_ohe_features(input_df):\n","    # ordinal encording (label encording)した特徴量\n","    tmp = input_df[\"popularity\"].astype(str).str.zfill(2)\n","    tmp = pd.Series([i[0] for i in tmp])\n","    _input_df = input_df.fillna(0).copy()\n","    _input_df[\"pop10regeion\"] = tmp + input_df[\"region\"]\n","    cols = [\"region\", \n","            \"pop10regeion\"\n","            ]\n","    encoder = ce.OneHotEncoder()\n","    output_df = encoder.fit_transform(_input_df[cols]).add_prefix(\"OHE_\")\n","    return output_df.add_prefix(\"MLP__\")\n","\n","\n","def get_mlp_tmpo_features(input_df):\n","    # tmpo に関する特徴量\n","    _df = input_df[\"tempo\"].str.split(\"-\").apply(pd.Series).astype(float)\n","    _df.columns = [\"tempo_low\", \"tempo_high\"]\n","    output_df = _df.fillna(0).copy()\n","    output_df[\"diff_tempo\"] = _df[\"tempo_high\"] - _df[\"tempo_low\"]\n","    return output_df.add_prefix(\"MLP__\")\n","\n","\n","def get_mlp_binned_popularity_features(input_df):\n","    # popularity の10の位と1の位の特徴量\n","    tmp = input_df[\"popularity\"].astype(str).str.zfill(2)\n","    tmp = [[i[0], i[1]] for i in tmp]\n","    output_df = pd.DataFrame(tmp, columns=[\"popularity10\", \"popularity01\"])\n","    return output_df.astype(int).add_prefix(\"MLP__\")\n","\n","# 集約特徴量作成時に使用\n","def max_min(x):\n","    return x.max() - x.min()\n","\n","def q75_q25(x):\n","    return x.quantile(0.75) - x.quantile(0.25)\n","\n","\n","def get_mlp_agg_region_features(input_df):\n","    # region をキーにした集約特徴量\n","    _input_df = pd.concat([\n","                           get_mlp_tmpo_features(input_df),\n","                           input_df], axis=1)\n","    group_key = \"region\"\n","    group_values = ['popularity',\n","                    'duration_ms',\n","                    'acousticness',\n","                    'positiveness',\n","                    'danceability',\n","                    'loudness',\n","                    'energy',\n","                    'liveness',\n","                    'speechiness',\n","                    'instrumentalness']\n","    agg_methods = [\"z-score\",]\n","    encoder = GroupingEngine(group_key=group_key, group_values=group_values, agg_methods=agg_methods)\n","    output_df = encoder.fit_transform(_input_df).fillna(0)\n","    return output_df.add_prefix(\"MLP__\")\n","\n","\n","def get_mlp_agg_popularity10_region_features(input_df):\n","    tmp = input_df[\"popularity\"].astype(str).str.zfill(2)\n","    tmp = pd.Series([i[0] for i in tmp])\n","    _input_df = pd.concat([input_df, get_mlp_tmpo_features(input_df)], axis=1)\n","    _input_df[\"pop10regeion\"] = tmp + input_df[\"region\"]\n","    group_key = \"pop10regeion\"\n","    group_values = ['duration_ms',\n","                    'acousticness',\n","                    'positiveness',\n","                    'danceability',\n","                    'loudness',\n","                    'energy',\n","                    'liveness',\n","                    'speechiness',\n","                    'instrumentalness']\n","    agg_methods = [\"z-score\",]\n","    encoder = GroupingEngine(group_key=group_key, group_values=group_values, agg_methods=agg_methods)\n","    output_df = encoder.fit_transform(_input_df).fillna(0)\n","    return output_df.add_prefix(\"MLP__\")\n","\n","\n","def get_mlp_target_encode_features(input_df):\n","    kf = model_selection.KFold(n_splits=10, random_state=2021, shuffle=True)\n","    tmp = input_df[\"popularity\"].astype(str).str.zfill(2)\n","    tmp = pd.Series([i[0] for i in tmp])\n","    _input_df = input_df.copy()\n","    _input_df[\"pop10region\"] = tmp + input_df[\"region\"]\n","\n","    train_df = _input_df[_input_df[\"genre\"].notnull()]\n","    train_y = ce.OneHotEncoder().fit_transform(train_df[\"genre\"].astype(str))\n","    genre = ['country',\n","             'electronic',\n","             'folk',\n","             'hip-hop',\n","             'jazz',\n","             'latin',\n","             'classic',\n","             'other-light-music',\n","             'pop',\n","             'religious',\n","             'rock']\n","    train_y.columns = genre\n","    out_lst = []\n","    for col in genre:\n","        _y = train_y[col]\n","        encoder = TargetEncodingEngine(use_columns=[\"region\", \"pop10region\"],\n","                                       cv=kf.split(train_df, _y))\n","        encoder.fit(input_df=train_df, y=_y)\n","\n","        out_df = encoder.transform(_input_df).add_suffix(f\"={col}\")\n","        out_lst.append(out_df)\n","    \n","    output_df = pd.concat(out_lst, axis=1).fillna(0)\n","    return output_df.add_prefix(\"MLP__\")\n","\n","\n","def get_cross_pseudo_features(input_df):\n","    return input_df[[\"index\", \"flag\"]].copy()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"iclCu7Z3fyat","executionInfo":{"status":"ok","timestamp":1620537207485,"user_tz":-540,"elapsed":50374,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}}},"source":["# 上で作った関数を実行し、train, test それぞれで前処理を施す関数を定義: get_train_data, get_test_data\n","def preprocess(input_df, funcs, task=\"train\"):\n","    df_lst = []\n","    for func in funcs:\n","        file_name = os.path.join(FEATURE, f\"{task}_{func.__name__}.pkl\")\n","        if os.path.isfile(file_name):\n","            _df = Util.load(file_name)\n","        else:\n","            _df = func(input_df)\n","            Util.dump(_df, file_name)\n","        df_lst.append(_df)\n","    output_df = pd.concat(df_lst, axis=1)  \n","    return output_df\n","\n","\n","def get_train_data(train, test):\n","    # whole_funcs: train+test の全体集合を対象とした処理\n","    whole_funcs = [get_numerical_features,\n","                   get_tmpo_features,\n","                   get_binned_popularity_features,get_ce_features, \n","                   get_oe_features,\n","                   get_agg_region_features,\n","                   get_agg_pop10region_features,\n","                   get_num_nan_features,\n","                   get_target_encode_features,\n","                   get_knn_numerical_features, \n","                   get_knn_ohe_features,\n","                   get_knn_tmpo_features,\n","                   get_knn_num_nan_features,\n","                   get_knn_target_encode_features,\n","                   get_mlp_numerical_features,\n","                   get_mlp_tmpo_features,\n","                   get_mlp_binned_popularity_features,\n","                   get_mlp_ce_features,\n","                   get_mlp_ohe_features,\n","                   get_mlp_agg_region_features,\n","                   get_mlp_agg_popularity10_region_features,\n","                   get_mlp_target_encode_features,\n","                   get_cross_pseudo_features]\n","\n","    whole_df = pd.concat([train, test]).reset_index(drop=True)\n","    whole_out = preprocess(whole_df, whole_funcs, task=\"whole_\")  # whole funcs による前処理\n","\n","    train_x = whole_out.iloc[:len(train)]\n","    \n","    return train_x     \n","\n","\n","def get_test_data(train, test):\n","\n","    # whole_funcs: train+test の全体集合を対象とした処理\n","    whole_funcs = [get_numerical_features,\n","                   get_tmpo_features,\n","                   get_binned_popularity_features,get_ce_features, \n","                   get_oe_features,\n","                   get_agg_region_features,\n","                   get_agg_pop10region_features,\n","                   get_num_nan_features,\n","                   get_target_encode_features,\n","                   get_knn_numerical_features, \n","                   get_knn_ohe_features,\n","                   get_knn_tmpo_features,\n","                   get_knn_num_nan_features,\n","                   get_knn_target_encode_features,\n","                   get_mlp_numerical_features,\n","                   get_mlp_tmpo_features,\n","                   get_mlp_binned_popularity_features,\n","                   get_mlp_ce_features,\n","                   get_mlp_ohe_features,\n","                   get_mlp_agg_region_features,\n","                   get_mlp_agg_popularity10_region_features,\n","                   get_mlp_target_encode_features,\n","                   get_cross_pseudo_features]\n","\n","    whole_df = pd.concat([train, test]).reset_index(drop=True)\n","    whole_out = preprocess(whole_df, whole_funcs, task=\"whole_\")  # whole funcs による前処理\n","\n","    test_x = whole_out.iloc[len(train):].reset_index(drop=True)\n","    \n","    return test_x     "],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sBCUI9kfzsk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620537237059,"user_tz":-540,"elapsed":79943,"user":{"displayName":"鳥羽真仁","photoUrl":"","userId":"00518710488487886706"}},"outputId":"4fdf7e89-1768-45cc-be53-65958f8b50e6"},"source":["# get features\n","train_x = get_train_data(train, test)\n","test_x = get_test_data(train, test)\n","train_y = train[\"genre\"]\n","\n","print(train_x.shape)\n","\n","if train_x.shape[1] != test_x.shape[1]:\n","    raise Exception(\"Not much number of features\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning:\n","\n","is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n","\n","/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning:\n","\n","is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n","\n","/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning:\n","\n","is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n","\n","/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning:\n","\n","is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n","\n","/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning:\n","\n","is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n","\n"],"name":"stderr"},{"output_type":"stream","text":["(6624, 464)\n"],"name":"stdout"}]}]}